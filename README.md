# Machine Activity Project

This repository contains a project that aims to gather information by analyzing machine positioning data, including coordinates and basic activity information. It aims to provide insights into the **routine** and **behavior** of the machine. This information can be highly valuable for evaluating whether the behavior aligns with the planning or if there are any **deviations**.

The data was obtained from a report generated by a JCB 3CX backhoe loader during pavement and drainage activities in the year 2022.

## Main Objectives

1. Convert data into information by publishing results in a web-accessible format for any device.

## Secondary Objectives

1. **Map activity over time with a map view**: Visualize the machine's activity on a map over different time periods.

2. **Detect operation deviations**: Use GPS mapping to show when services occurred outside the primary activity.

3. **Assess the quantity and quality of records**: Evaluate the information flow sent by the machine.

4. **Understand the recorded activities**: Identify and filter the **main activities**.

5. Identify the **routine** and **behavior** of the machine.

## Overview

This project demonstrates the application of data engineering to automate data collection and analysis, providing valuable insights into machine usage.

### Process Steps

- **Data Extraction from GPS**: The system reads CSV, Google Sheets, and Parquet files containing GPS coordinates of machine activity. These data are essential for tracking equipment location and movement over time.

- **Dataframe Understanding**: Understanding the data, identifying relevant information, how they are distributed, and their relationship with other variables such as time (hour, day, month) or coordinates (latitude and longitude).

- **Data Size**: Check the quantity of records by an interval of hour, day, and month.

- **Data Quality**: Understand how the available data can be useful.

Quality conditions must be true:
3.3 Quantity the key is on = engine is on
3.4 Quantity the key is off = engine is off

- **Data Normalization**: Normalize date and time data and location coordinates.

- **Data Transformation**: Apply distance calculation functions and filter relevant variables.

- **Reporting**: Create reports through aggregation and answer questions about equipment behavior:

- Web Application (Streamlit): A web application built with Streamlit allows users to view reports on any device in a web format:

- Describe the operation: Which day had the longest operation time? What is the longest distance traveled in a day, month, or year? On which day was the shortest operation time? Which days had the most extended operation hours?

- Dashboards: Hours per week chart: Mon, Tue, Wed, Thu, Fri, Sat, Sun. Distance per week chart: Mon, Tue, Wed, Thu, Fri, Sat, Sun.

- Location Map: Allows filtering to find out where the machine was present during a specific period.

## Next Steps:

For a complete analysis, it is necessary to collect data related to the environment in which the equipment is used and establish a temporal link to assess how the environment affects equipment activity.

### 1. Include More Datasets to Create a Datalake:

Include relevant information such as:
- Operator identification
- Occurrence of rain
- Refueling
- Preventive maintenance
- Corrective maintenance
- Type of activity performed (e.g., drainage with concrete pipe Ã˜40cm)
- Weather conditions
- Known locations

### 2. Data Analysis:

Combine and analyze GPS and reporting data. Calculate equipment productivity, identify operational bottlenecks, and generate detailed reports.

### 3. Generation of Project Completion Time:

Based on the calculated real productivity, the system generates optimistic, realistic, and pessimistic completion times. This aids in project management and the identification of potential delays.

### 4. Lessons Learned:

Collect decision-making data from managers to measure the effectiveness of actions.

### 5. Best Practices:

Suggest best practices to assist in future decision-making, based on past events.

### 6. AI Preparation:

Provide a normalized dataset with actions considered as **BEST PRACTICES** to generate reliable data for machine learning environments.

### 7. Use AI:

Suggest actions to optimize productivity through a trained model, both during operation and decision-making.

## Configuration Requirements:

To set up and run this project, you'll need the following dependencies:

- [Python 3](https://www.python.org/)
- [Streamlit](https://streamlit.io/)
- Pandas